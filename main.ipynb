{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "#replace this: from selenium import webdriver\n",
    "from seleniumwire import webdriver\n",
    "\n",
    "# replace this: import undetected_chromedriver as uc\n",
    "import seleniumwire.undetected_chromedriver as uc\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import random\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###CODE make one big function of it all:\n",
    "\n",
    "session_object = requests.Session()\n",
    "\n",
    "payload={}\n",
    "headers = {\n",
    "  'Cookie': 'c6dffb09df089a180b8aa9ba431e51d3=t5nsr6r8v74vdbniq945hqe6ug'\n",
    "}\n",
    "\n",
    "\n",
    "###FUNCTION\n",
    "def read_data_tables(x):\n",
    "    # response = session_object.request(\"GET\", url, headers=headers, data=payload)\n",
    "    # x=response.text\n",
    "\n",
    "    ######################\n",
    "    ##we got the site , now we store as html file so we can read_html with panda\n",
    "\n",
    "    with open('x.html', 'w', encoding=\"utf-8\") as file:\n",
    "        file.write(x)\n",
    "\n",
    "\n",
    "    #### IMPORTANT!!!  read with pandas\n",
    "    df=pd.read_html('x.html')\n",
    "\n",
    "    df_main=pd.DataFrame()\n",
    "\n",
    "    ### Loop through extracted tables and add them to one df_main panda!\n",
    "    for i in df:\n",
    "        i=pd.DataFrame(data=i)\n",
    "        #i=i.transpose()\n",
    "        df_main=pd.concat([df_main, i] , ignore_index=True)\n",
    "    \n",
    "    ### inverse Columns with Rows!\n",
    "    df_main=df_main.transpose()\n",
    "\n",
    "    #save to CSV, and replace the header (unnecessary numbers here) with 1st Row (which is actually header here)\n",
    "\n",
    "    ##better to create file outside of function and only add data at this point\n",
    "    #df_main.to_csv('view.csv', header=False, index=False)\n",
    "\n",
    "\n",
    "    if os.path.exists(\"x.html\"):    \n",
    "        os.remove(\"x.html\")\n",
    "    else:\n",
    "        print(\"The file does not exist\")\n",
    "\n",
    "    return df_main"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Click on each element in each row, open a new page and scrape data (by running read_data_tables(x) function)\n",
    "    ->save down each scrape into CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_each_link():\n",
    "    for i in range(1,11):\n",
    "        driver.find_element(By.XPATH, f'/html/body/div[2]/div[5]/div/div[2]/div/div[2]/div[4]/div/div[1]/table/tbody/tr[{i}]/td[5]/a').click()\n",
    "                                        \n",
    "        #function here to scrape data from site and then go back to previous window so next element can be clicked\n",
    "        time.sleep(3)\n",
    "\n",
    "        x=driver.page_source\n",
    "        \n",
    "\n",
    "        #save to CSV, and replace the header (unnecessary numbers here) with 1st Row (which is actually header here)\n",
    "\n",
    "        ##better to create file outside of function and only add data at this point\n",
    "        df_main=read_data_tables(x)\n",
    "\n",
    "        #df_main.drop(index=df_main.index[0], axis=0, inplace=True) #delete 1st row cuz header is repeating..there's alternatives to doing this\n",
    "\n",
    "        df_main.to_csv('view.csv',mode='a', header=False, index=False) #save each scrape to CSV\n",
    "        driver.back()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Next Button Pagination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def next_page(): \n",
    "#     while True: \n",
    "#         if len(driver.find_elements(By.CSS_SELECTOR, '.uk-pagination-next')) > 0: #if the next button exists\n",
    "#             open_each_link()                                                        #go through each listing, open each link\n",
    "#             driver.find_element(By.CSS_SELECTOR, '.uk-pagination-next').click()         #at the end click the next page button\n",
    "#         else:\n",
    "#             break  #if the next button doesn't exist, break out of the loop and stop function\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #replace this: from selenium import webdriver\n",
    "# from seleniumwire import webdriver\n",
    "\n",
    "# # replace this: import undetected_chromedriver as uc\n",
    "# import seleniumwire.undetected_chromedriver as uc\n",
    "\n",
    "# from selenium.webdriver.common.by import By\n",
    "# import time\n",
    "# import random\n",
    "# import csv\n",
    "\n",
    "\n",
    "\n",
    "url='https://global-standard.org/find-suppliers-shops-and-inputs/certified-suppliers/database'\n",
    "\n",
    "\n",
    "\n",
    "##add this if to avoid errors\n",
    "if __name__ =='__main__':\n",
    "\n",
    "#################################### STOP BEING BLOCKED!!!  #################################################################################\n",
    "        #######  ADD OPTIONS for PROXY & USER DATA arguments with   ###################################\n",
    "\n",
    "    options = uc.ChromeOptions()\n",
    "\n",
    "    ##Proxy: ###\n",
    "    \n",
    "\n",
    "\n",
    "    ##Load your Chrome profile, can help with some sites(speed, ID), can get you blocked on others:\n",
    "    options.add_argument(r'--user-data-dir=C:\\Users\\matzu\\AppData\\Local\\Google\\Chrome\\User Data\\Default')\n",
    "\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "\n",
    "\n",
    "    ### METHOD:\n",
    "    driver = uc.Chrome(options=options,  seleniumwire_options={})\n",
    "\n",
    "\n",
    "    #### Run these, maybe not necessary if you rotate user agents;\n",
    "        ##it does make the code quicker if user together with:\n",
    "            #   options.add_argument(r'--user-data-dir=C:\\Users\\matzu\\AppData\\Local\\Google\\Chrome\\User Data\\Default')\n",
    "    #below migth not be necessary?\n",
    "    # driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "    # driver.execute_cdp_cmd('Network.setUserAgentOverride', {\"userAgent\": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.53 Safari/537.36'})\n",
    "    # driver.execute_script(\"return navigator.userAgent;\")\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "\n",
    "#test it:\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"xFormForm-0-submit\"]/span')))\n",
    "\n",
    "    driver.find_element(By.CSS_SELECTOR, '#xFormForm-0-submit').click()\n",
    "\n",
    "    time.sleep(10)\n",
    "\n",
    "    driver.find_element(By.CSS_SELECTOR, '.uk-pagination-next').click()\n",
    "    print(len(driver.find_elements(By.CSS_SELECTOR, '.uk-pagination-next')))\n",
    "\n",
    "\n",
    "    while True: \n",
    "        if len(driver.find_elements(By.CSS_SELECTOR, '.uk-pagination-next')) > 0: #if the next button exists\n",
    "            open_each_link()\n",
    "            time.sleep(5)                                                       #go through each listing, open each link\n",
    "            driver.find_element(By.CSS_SELECTOR, '.uk-pagination-next').click()         #at the end click the next page button\n",
    "        else:\n",
    "            break  #if the next button doesn't exist, break out of the loop and stop function\n",
    "\n",
    "\n",
    "    driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df8e81faa7d1b4401e2711a348e813f13c6811ca5306930034f1346d4c63e8a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
